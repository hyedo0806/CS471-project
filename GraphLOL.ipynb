{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install our code\n",
    "\n",
    "First, we should clone our code on our directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hyedo0806/CS471-project\n",
    "!cd ./CS471-project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we should download necessary files on our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Preprocessed dataset (https://www.kaggle.com/datasets/paololol/league-of-legends-ranked-matches?select=stats1.csv)\n",
    "!gdown https://drive.google.com/uc?id=1OTsNTJ8jJ4QZZSoncKGrapM4kl-J6UtD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def normalization_df(df):\n",
    "  normalized_df=(df-df.mean())/df.std()\n",
    "  return normalized_df\n",
    "\n",
    "\n",
    "def read_graph_nodes_relations(data):\n",
    "\n",
    "  dataFiltered = data.groupby(\"matchid\").filter(lambda x: len(x) == 10)\n",
    "  # data를 refine 했기 때문에 length 이 10이 아닐수도 있음\n",
    "\n",
    "  graph = dataFiltered['matchid'].unique()\n",
    " \n",
    "  return [i for i in range(graph.shape[0]*10)], graph\n",
    "\n",
    "def edgeAndDegree(num, cutMode, position_df = None):\n",
    "  # 이 부분 attention 해서 봐야 할 것 같음\n",
    "  # edge 를 순서대로 나열하는 곳\n",
    "\n",
    "  if cutMode != \"N\":\n",
    "    edges = torch.zeros((50*num,2))\n",
    "    cnt = 0\n",
    "    for k in tqdm(range(num)):\n",
    "      # connecting intra-team\n",
    "      for i in range(1,5):\n",
    "        for j in range(i, 5):\n",
    "          if (position_df['TOP'][i] == 1 and (position_df['BOT'][j] == 1 or position_df['SUPPORT'][j])) or (position_df['TOP'][j] == 1 and (position_df['BOT'][i] == 1 or position_df['SUPPORT'][i])):\n",
    "            if (position_df['TOP'][i] == 1):\n",
    "              top_id = i\n",
    "              bot_id = j\n",
    "            else:\n",
    "              top_id = j\n",
    "              bot_id = i\n",
    "            \n",
    "            if cutMode == \"2\":\n",
    "              # 양방향 컷\n",
    "              pass\n",
    "            elif cutMode == \"1\":\n",
    "              # 단방향 컷\n",
    "              edges[cnt][0] = bot_id+k*10\n",
    "              edges[cnt][1] = top_id+k*10\n",
    "              cnt +=1\n",
    "            else:\n",
    "              print(\"cutMode error!\")\n",
    "              assert(0)\n",
    "            \n",
    "          else:\n",
    "            # 컷이랑 관련 없는 경우\n",
    "            edges[cnt][0] = i+k*10\n",
    "            edges[cnt][1] = j+k*10\n",
    "            edges[cnt+1][0] = i+5+k*10\n",
    "            edges[cnt+1][1] = j+5+k*10  \n",
    "            cnt +=2\n",
    "      \n",
    "      # inter-team connecting\n",
    "      for i in range(1,5):\n",
    "        edges[cnt][0] = i+k*10\n",
    "        edges[cnt][1] = i+5+k*10\n",
    "        edges[cnt+1][0] = i+5+k*10\n",
    "        edges[cnt+1][1] = i+k*10\n",
    "        cnt +=2\n",
    "\n",
    "\n",
    "  else:\n",
    "    edges = torch.zeros((50*num,2))\n",
    "    cnt = 0\n",
    "    for k in tqdm(range(num)):\n",
    "      for i in range(5):\n",
    "        for j in range(5):\n",
    "          if i!=j : \n",
    "            edges[cnt][0] = i+k*10\n",
    "            edges[cnt][1] = j+k*10\n",
    "            edges[cnt+1][0] = i+5+k*10\n",
    "            edges[cnt+1][1] = j+5+k*10   \n",
    "          else: \n",
    "            edges[cnt][0] = i+k*10\n",
    "            edges[cnt][1] = i+5+k*10\n",
    "            edges[cnt+1][0] = i+5+k*10\n",
    "            edges[cnt+1][1] = i+k*10\n",
    "          cnt +=2\n",
    "\n",
    "            \n",
    "  degrees = torch.empty((10 * num,))\n",
    "  degrees.fill_(5)\n",
    "\n",
    "  return edges.to(device), degrees.to(device)\n",
    "\n",
    "\n",
    "class GraphSageLayer(nn.Module):\n",
    "  def __init__(self, dim_in, dim_out, agg):\n",
    "    super(GraphSageLayer, self).__init__()\n",
    "\n",
    "    self.dim_in = dim_in\n",
    "    self.dim_out = dim_out\n",
    "    self.agg = agg\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "    if self.agg == 'gcn':\n",
    "      self.weight = nn.Linear(self.dim_in, self.dim_out, bias=False, dtype=torch.float32) # W_l\n",
    "      self.bias = nn.Linear(self.dim_in, self.dim_out, bias=False, dtype=torch.float32) # B_l\n",
    "\n",
    "    elif self.agg == 'mean':\n",
    "      self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False, dtype=torch.float32) # W_l\n",
    "\n",
    "    elif self.agg == 'maxpool':\n",
    "      self.linear_pool = nn.Linear(self.dim_in, self.dim_in, bias=True, dtype=torch.float32) # W_{pool}, b\n",
    "      self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False, dtype=torch.float32) # W_l\n",
    "                      \n",
    "  def forward(self, feat, edge, degree):\n",
    "    if self.agg == 'gcn':   \n",
    "      \n",
    "      indices = edge[:,1].long()\n",
    "      feat_t = feat[indices]\n",
    "      idx_h = edge[:, 0]\n",
    "      agg_neighbor = torch.zeros(feat.shape[0], feat.shape[1], dtype=torch.float32).to(device).index_add_(0, idx_h.long(), feat_t.float())\n",
    "\n",
    "      inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree).unsqueeze(-1)\n",
    "      agg = agg_neighbor * inv_degree\n",
    "      return F.normalize(self.act(self.weight(agg) + self.bias(feat)), 2, -1)\n",
    "    \n",
    "    elif self.agg == 'mean':\n",
    "\n",
    "      feat_t = feat[edge[:, 1].long()]\n",
    "      idx_h = edge[:, 0]\n",
    "      agg_neighbor = torch.zeros(feat.shape[0], feat.shape[1], dtype=torch.float32).index_add_(0, idx_h.long(), feat_t)\n",
    "      \n",
    "      inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree).unsqueeze(-1)\n",
    "      agg = agg_neighbor * inv_degree\n",
    "      return F.normalize(self.act(self.weight(torch.cat((agg, feat), 1))), 2, -1)\n",
    "\n",
    "    elif self.agg == 'maxpool':\n",
    "      feat = self.act(self.linear_pool(feat))\n",
    "      feat_t = feat[edge[:, 1]]\n",
    "      idx_h = edge[:, 0]\n",
    "      scatter_idx = idx_h.unsqueeze(-1).repeat(1, feat.shape[1])\n",
    "      \n",
    "      agg = torch.zeros(feat.shape[0], feat.shape[1], dtype=torch.float32).scatter_reduce(0, scatter_idx, feat_t, reduce='amax', include_self=False)\n",
    "    \n",
    "      return F.normalize(self.act(self.weight(torch.cat((agg, feat), 1))), 2, -1)\n",
    "\n",
    "\n",
    "class GraphSage(nn.Module):\n",
    "  def __init__(self, num_layers, dim_in, dim_hidden, dim_out, agg):\n",
    "                    # 2,       dim_feat,     128,       2,    'gcn'\n",
    "    super(GraphSage, self).__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "    self.dim_in = dim_in\n",
    "    self.dim_hidden = dim_hidden\n",
    "    self.dim_out = dim_out\n",
    "    self.agg = agg\n",
    "\n",
    "    layers = [GraphSageLayer(self.dim_in, self.dim_hidden, agg)]\n",
    "    for _ in range(num_layers - 1):\n",
    "      layers.append(GraphSageLayer(self.dim_hidden, self.dim_hidden, agg))\n",
    "\n",
    "    self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    self.classifier = nn.Linear(self.dim_hidden, self.dim_out, dtype=torch.float32)\n",
    "\n",
    "  def forward(self, feat, edge, degree):\n",
    "    list_feat = [feat]\n",
    "\n",
    "    for layer in self.layers:\n",
    "      list_feat.append(layer(list_feat[-1], edge, degree))\n",
    "    \n",
    "    out = self.classifier(list_feat[-1])\n",
    "\n",
    "    return out\n",
    "\n",
    "                              \n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Classifier, self).__init__()\n",
    "\n",
    "    layers = []\n",
    "  \n",
    "    layers.append(nn.Linear(32, 16, dtype=torch.float32))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(16, 1, dtype=torch.float32))\n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    self.classifier = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.classifier(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "### trainset index를 셔플하지 않고 그래도 순차적으로 사용하면 이 코드를 사용할 수 있으나, 아래와 같이 index를 random하게 사용하면 다른 코드를 작성해야함. 하지만 계산 시간이 걸린다.\n",
    "def win_loss(out):\n",
    "  new_x = out.clone()  # 새로운 텐서를 생성하여 결과를 저장할 준비\n",
    "\n",
    "  for i in tqdm(range(0, out.shape[0], 10)):  # 10개씩 묶음을 만들기 위해 0부터 18000까지 10씩 증가하는 인덱스 사용\n",
    "      batch = out[i:i+10]  # 10개씩 묶음을 선택\n",
    "\n",
    "      first_sum = torch.sum(batch[:5])  # 묶음의 앞쪽 5개 요소의 합\n",
    "      second_sum = torch.sum(batch[5:])  # 묶음의 다음 5개 요소의 합\n",
    "\n",
    "      if first_sum > second_sum:\n",
    "          new_x[i:i+5] = torch.full((5, 1), 0.9)  # 앞쪽 5개 요소의 합이 큰 경우 0.9로 대체\n",
    "          new_x[i+5:i+10] = torch.full((5, 1), 0.1)  # 앞쪽 5개 요소의 합이 큰 경우 0.9로 대체\n",
    "      else:\n",
    "          new_x[i:i+5] = torch.full((5, 1), 0.1)  # 앞쪽 5개 요소의 합이 큰 경우 0.9로 대체\n",
    "          new_x[i+5:i+10] = torch.full((5, 1), 0.9)  # 앞쪽 5개 요소의 합이 큰 경우 0.9로 대체\n",
    " \n",
    "\n",
    "  return new_x\n",
    "\n",
    "\n",
    "def train(model, agg, feat, edge, degree, label, dim_hidden=128, dim_out=7,\n",
    "          lr=0.001, num_epoch=200, writer = None):\n",
    "\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "  loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  best_valid = 0.0\n",
    "\n",
    "  list_valid_f1 = []\n",
    "  list_loss = []\n",
    "\n",
    "  for epoch in range(num_epoch):\n",
    "    ## ----- random index for training ( lab3 참고 )\n",
    "\n",
    "    cut_down = (int(0.8 * num_node)//10)*10\n",
    "    valid = (int(0.1 * num_node)//10)*10\n",
    "\n",
    "    idx_train = [ i for i in range(cut_down)]\n",
    "    idx_valid = [i for i in range(cut_down,cut_down+valid)]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    target = label[idx_train]\n",
    "\n",
    "    pred = model(feat, edge, degree)\n",
    "    loss = loss_fn(pred[idx_train], target)\n",
    "    loss.backward()\n",
    "\n",
    "    # train loss 기록하는 함수\n",
    "    optimizer.step()\n",
    "\n",
    "    list_loss.append(loss.item())\n",
    "\n",
    "    #### Validation ####\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      target = label[idx_valid]\n",
    "\n",
    "      pred = model(feat, edge, degree)\n",
    "      _pred = pred[idx_valid]\n",
    "      _pred[_pred>0] = 1\n",
    "      _pred[_pred<0] = 0\n",
    "\n",
    "      # _, _pred = torch.max(pred[idx_valid], 0)\n",
    "      _pred = _pred.detach().cpu()\n",
    "\n",
    "      # print(_pred)\n",
    "      f1_val = f1_score(target, _pred, average='micro')\n",
    "\n",
    "      list_valid_f1.append(f1_val)\n",
    "      print(f\"F1 Score: {f1_val}\")\n",
    "\n",
    "      if f1_val > best_valid:\n",
    "        best_valid = f1_val\n",
    "\n",
    "    model.train()\n",
    "  \n",
    "  return list_loss, list_valid_f1\n",
    "\n",
    "def visualize(num_epoch, list_loss, list_valid_f1, title):\n",
    "  t = np.arange(num_epoch)\n",
    "\n",
    "  fig, ax1 = plt.subplots()\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.set_ylabel('Loss')\n",
    "  line1 = ax1.plot(t, list_loss, color='blue', label='Loss')\n",
    "\n",
    "  ax2 = ax1.twinx()\n",
    "  ax2.set_ylabel('F1 Score (Micro)')\n",
    "  line2 = ax2.plot(t, list_valid_f1, color='orange', label='F1 Score (Micro)')\n",
    "\n",
    "  lines = line1 + line2\n",
    "  labels = [line.get_label() for line in lines]\n",
    "\n",
    "  ax1.legend(lines, labels, loc=\"upper left\", bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.savefig(\"f{}_loss.png\".format(num_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# cutMode has three types\n",
    "\n",
    "# \"N\": No cut, original\n",
    "# \"1\": one-way cut. cut down from top to bottom\n",
    "# \"2\": two-way cut. cut down from top to bottom and from bottom to top\n",
    "cutMode = input(\"cutMode?\")\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "trainsetEncoded = pd.read_csv(\"trainset.txt\", delimiter=\"\\t\")\n",
    "trainsetEncoded = trainsetEncoded.drop([\"Unnamed: 0\", \"team\"], axis=1)\n",
    "\n",
    "nodes, graphs = read_graph_nodes_relations(trainsetEncoded[[\"matchid\"]])\n",
    "\n",
    "## ----- X : feature, Y : label \n",
    "featureE = normalization_df(trainsetEncoded.drop(['win', 'matchid'], axis=1))\n",
    "label = trainsetEncoded[[\"win\"]]\n",
    "\n",
    "## ----- data 를 tensor 형식으로 변환\n",
    "featN = featureE.to_numpy().astype(np.float32)\n",
    "featT = torch.from_numpy(featN).to(device) \n",
    "\n",
    "labelN = label.to_numpy().astype(np.float32)\n",
    "labelT = torch.from_numpy(labelN).to(device)\n",
    "\n",
    "num_node = featureE.shape[0]\n",
    "dim_feat = featureE.shape[1]\n",
    "\n",
    "## ----- edge & degree\n",
    "\n",
    "# topBottomCut 이란 top 과 Bottom 두명 사이의 connection을 없애는 작업을 의미한다.\n",
    "if cutMode != \"N\":\n",
    "  edgeT, degreeT = edgeAndDegree(num_node//10, cutMode, position_df = trainsetEncoded[['BOT', 'JUNGLE', 'MID', 'SUPPORT', 'TOP']])\n",
    "else:\n",
    "  edgeT, degreeT = edgeAndDegree(num_node//10, cutMode)\n",
    "\n",
    "## -----  모델 구조 lab3 참고\n",
    "mode = 'gcn'\n",
    "model = GraphSage(2, dim_feat, 32, 1, mode).to(device)\n",
    "# writer 는 tensorboard 때문에 존재.\n",
    "list_loss_gcn, list_valid_f1_gcn = train(model, mode, featT, edgeT, degreeT, labelT, writer=None)\n",
    "visualize(200, list_loss_gcn, list_valid_f1=list_valid_f1_gcn, title = \"loss and F1 score\")\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
